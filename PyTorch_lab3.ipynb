{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlaaHesham_ Lab3_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u0QZrJpzZNu",
        "colab_type": "text"
      },
      "source": [
        "<h4 align=\"right\">10th of February 2020</h4>\n",
        "<h1 align=\"center\">Neural Networks and Deep Learning (CIE 555)</h1>\n",
        "<h2 align=\"center\">Lab 3: PyTorch</h2> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XixbXXcaLUVa",
        "colab_type": "text"
      },
      "source": [
        "PyTorch is an open-source machine learning framework developed by Facebook AI. It is designed to be fast and feel native.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOGQrVyQYNX0",
        "colab_type": "text"
      },
      "source": [
        "###(1) Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VECBUbyVYpzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDlrfbxJYS_D",
        "colab_type": "code",
        "outputId": "d6f72822-8535-420b-eaf4-d911f13af901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Tensors\n",
        "#Can be initialized from list, tuple, numpy array\n",
        "x = [[1,2,3],[4,5,6]]\n",
        "xten = torch.tensor(x, dtype=torch.float32) #xten = torch.tensor(x, dtype=torch.float32, device=torch.device('cpu'))\n",
        "print(xten)\n",
        "print(\"\")\n",
        "print(xten.size()) #like .shape in tensorflow and numpy\n",
        "print(xten.size()[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "torch.Size([2, 3])\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIGrmPz_RUyy",
        "colab_type": "code",
        "outputId": "c197920e-8a95-471a-81e7-3952562e190a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Different tensor initializations\n",
        "x1 = torch.rand((2,3))\n",
        "x2 = torch.zeros((1,2))\n",
        "x2_like = torch.randn_like(x2)\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(x2_like)\n",
        "print(torch.numel(x1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6412, 0.8583, 0.3636],\n",
            "        [0.0229, 0.1651, 0.0092]])\n",
            "tensor([[0., 0.]])\n",
            "tensor([[-0.9715,  0.4078]])\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EUBUlTTV2xX",
        "colab_type": "code",
        "outputId": "763cc6c7-e44e-4da2-c656-2e760fb7b980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Transpose and Inverse\n",
        "x1 = torch.randn((3,3))\n",
        "print(x1)\n",
        "print()\n",
        "print(torch.t(x1))\n",
        "print()\n",
        "print(torch.inverse(x1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0083,  0.6098,  2.8579],\n",
            "        [ 1.9654, -0.7473,  0.9886],\n",
            "        [ 1.0694,  0.2705,  1.0313]])\n",
            "\n",
            "tensor([[ 0.0083,  1.9654,  1.0694],\n",
            "        [ 0.6098, -0.7473,  0.2705],\n",
            "        [ 2.8579,  0.9886,  1.0313]])\n",
            "\n",
            "tensor([[-0.3241,  0.0450,  0.8549],\n",
            "        [-0.3027, -0.9515,  1.7510],\n",
            "        [ 0.4154,  0.2029, -0.3761]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEbEuVay0WvY",
        "colab_type": "code",
        "outputId": "e674993f-5491-49c4-9dc5-6542ca62e552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Concatenation\n",
        "x0 = torch.tensor([[1,2,3]])\n",
        "x = torch.cat((x0,x0),0)\n",
        "print(x)\n",
        "print()\n",
        "#Select certain columns or rows\n",
        "ind = torch.index_select(x,1,torch.tensor([0,2]))\n",
        "print(ind)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "\n",
            "tensor([[1, 3],\n",
            "        [1, 3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeLVt3bk2VT_",
        "colab_type": "code",
        "outputId": "554a6131-9e71-44fb-a1c1-f0667c60dba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reshaping\n",
        "x = torch.tensor([[1,2,3],[4,5,6]])\n",
        "y = torch.reshape(x,(1,-1))\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3, 4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfJJZzRc4ywK",
        "colab_type": "code",
        "outputId": "a9bb3bed-fbd8-4411-947c-f736ad367843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "###\n",
        "x = torch.randn((2,3))\n",
        "print(x)\n",
        "x = torch.clamp(x,min=0)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7995,  0.6985, -0.3660],\n",
            "        [-0.6231,  0.6398, -0.5463]])\n",
            "tensor([[0.7995, 0.6985, 0.0000],\n",
            "        [0.0000, 0.6398, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPYH0FH5MOZ",
        "colab_type": "code",
        "outputId": "a4b76d45-f23f-4314-ef45-3f1dfa71d8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Mathematical Operations\n",
        "x = torch.tensor([[-1,2,3],[4,5,6]])\n",
        "y = torch.tensor([[2,2,2],[2,2,2]])\n",
        "z = torch.add(x,y) #Addition\n",
        "print(z)\n",
        "z = torch.sub(x,y) #Subtraction\n",
        "z = torch.mul(x,y) #Element-wise multiplication\n",
        "z = torch.matmul(x,torch.t(y)) #Matrix multiplication\n",
        "z = torch.div(x,y) #Element-wise division\n",
        "z = torch.abs(x)\n",
        "#z = torch.mean(x)\n",
        "#z = torch.exp(x)\n",
        "z = torch.pow(x,y)\n",
        "#z = torch.sigmoid(x)\n",
        "z = torch.sum(y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf0KtlYCHqrN",
        "colab_type": "code",
        "outputId": "1bec73cc-4e92-4c2c-90ed-28495a7ff47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Get item of one-element torch tensor\n",
        "r = torch.tensor(5)\n",
        "print(r)\n",
        "w = r.item()\n",
        "print(w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5)\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b2iuKDUk_EV",
        "colab_type": "text"
      },
      "source": [
        "###(2) Introduction to nn and optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z60TDD_clWj3",
        "colab_type": "code",
        "outputId": "a7377ac1-509c-4057-f3aa-47d05899795e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Linear layer applies x*W +b\n",
        "a0 = torch.randn((130,4))\n",
        "L1 = nn.Linear(4,5)\n",
        "z1 = L1(a0)\n",
        "print(z1.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([130, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEtsNS7QtInH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Activation functions\n",
        "z1 = torch.randn((130,5))\n",
        "sig1 = nn.Sigmoid()\n",
        "#sig1 = nn.ReLU()\n",
        "#sig1 = nn.LeakyReLU()\n",
        "#sig1 = nn.Tanh()\n",
        "a1 = sig1(z1)\n",
        "\n",
        "#Softmax\n",
        "#out1 = nn.Softmax()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep0ktaE6uMc9",
        "colab_type": "code",
        "outputId": "7e5baa2b-da52-4c71-c1a6-655b663629d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "##Feedforward in logistic regression\n",
        "a0 = torch.randn((100,4))\n",
        "L1 = nn.Linear(4,1)\n",
        "z1 = L1(a0)\n",
        "sig1 = nn.Sigmoid()\n",
        "a11 = sig1(z1)\n",
        "\n",
        "#OR\n",
        "\n",
        "model = nn.Sequential(nn.Linear(4,1), nn.Sigmoid())\n",
        "print(model)\n",
        "a1 = model(a0)\n",
        "\n",
        "print(a11.size())\n",
        "print(a1.size())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=1, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucok1UwPxphM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Back propagation\n",
        "lossfun = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
        "optimizer.zero_grad() #zero gradients to not accumulate\n",
        "#loss = lossfun(a1, y_train) #calculate loss\n",
        "#loss.backward() #update weights based on loss\n",
        "#optimizer.step() #update optimizer for next iteration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHv85d4eKxhX",
        "colab_type": "text"
      },
      "source": [
        "- When we call loss.backward(), all it does is compute gradient of loss w.r.t all the parameters in loss that have requires_grad = True and store them in parameter.grad attribute for every parameter.\n",
        "\n",
        "- optimizer.step() updates all the parameters based on parameter.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlSwSCEhJ9Ih",
        "colab_type": "text"
      },
      "source": [
        "- In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. We do this by calling .zero_grad() function on the optimizer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzNs0KRqY4FC",
        "colab_type": "text"
      },
      "source": [
        "###(3) Implementing 2-layer Neural Network using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raSloG1pg2l7",
        "colab_type": "text"
      },
      "source": [
        "####Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdzG3f_gY9r3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikS9YmQIg4aV",
        "colab_type": "text"
      },
      "source": [
        "####Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGDoTpV5ZRSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()\n",
        "x = iris['data']\n",
        "y = iris['target']\n",
        "enc = OneHotEncoder(categories='auto')\n",
        "y = enc.fit_transform(y.reshape(-1,1)).A.astype(np.float32)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7U8QznZhDs3",
        "colab_type": "text"
      },
      "source": [
        "####Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWfGCwHAbK2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x, deriv=False):\n",
        "  sig = torch.sigmoid(x)\n",
        "  if deriv:\n",
        "    sig = sig*(1-sig)\n",
        "  return sig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf-0WXwIhH6B",
        "colab_type": "text"
      },
      "source": [
        "####Converting numpy arrays to torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RUBW6twZaAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_trainv = torch.tensor(x_train, requires_grad = False, dtype=torch.float32)\n",
        "y_trainv = torch.tensor(y_train, requires_grad = False, dtype=torch.float32)\n",
        "x_testv = torch.tensor(x_test, requires_grad = False, dtype=torch.float32)\n",
        "y_testv = torch.tensor(y_test, requires_grad = False, dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMxYqPHZhO9s",
        "colab_type": "text"
      },
      "source": [
        "####Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyDF2G6_ZrwY",
        "colab_type": "code",
        "outputId": "c722a051-1fb8-4512-ab05-ed3f3c619c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "n_in = x_trainv.size()[1]\n",
        "n_h = 5\n",
        "n_out = y_trainv.size()[1]\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "w0 = torch.randn((n_in,n_h))\n",
        "w1 = torch.randn((n_h,n_out))\n",
        "\n",
        "sigma = 0.01\n",
        "errors = []\n",
        "\n",
        "for i in range(2000):\n",
        "  #Feed forward\n",
        "  a0 = x_trainv\n",
        "  a1 = sigmoid(torch.matmul(a0,w0))\n",
        "  a2 = sigmoid(torch.matmul(a1,w1))\n",
        "  \n",
        "  #Back propagation using gradient descent\n",
        "  a2_error = y_trainv - a2\n",
        "  a2_delta = a2_error * sigmoid(a2, deriv=True)\n",
        "    \n",
        "  a1_error = torch.matmul(a2_delta,torch.transpose(w1,0,1))\n",
        "  a1_delta = a1_error * sigmoid(a1, deriv=True)\n",
        "    \n",
        "  w1 += torch.matmul(torch.transpose(a1,0,1),a2_delta) * sigma \n",
        "  w0 += torch.matmul(torch.transpose(a0,0,1),a1_delta) * sigma \n",
        "  \n",
        "  ####### TO BE DONE ######### 10% Time: 4 mins\n",
        "  #Write the error formula given the the error between the output layer and the labels: (a2_error)\n",
        "  error = torch.mean(torch.abs(a2_error)).item()\n",
        "  ############################\n",
        "  errors.append(error)\n",
        "  accuracy = (1 - error) * 100\n",
        "  \n",
        "\n",
        "#Plot the accuracy graph\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Training')\n",
        "plt.ylabel('Error')\n",
        "plt.show()\n",
        "        \n",
        "print(\"Training Accuracy \" + str(round(accuracy,2)) + \"%\")\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 87.18%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3gt7Jb1hRNQ",
        "colab_type": "text"
      },
      "source": [
        "####Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdeOR03zf-4W",
        "colab_type": "code",
        "outputId": "6349b598-d7c1-4992-d807-e69aac135da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Validation\n",
        "a0 = x_testv\n",
        "\n",
        "####### TO BE DONE ######### 10% Time: 7 mins\n",
        "#Write the validation line codes to test your model\n",
        "a1 = sigmoid(torch.matmul(a0,w0))\n",
        "a2 = sigmoid(torch.matmul(a1,w1))\n",
        "error = y_testv-a2\n",
        "error=torch.mean(torch.abs(error)).item()\n",
        "############################\n",
        "\n",
        "accuracy = (1 - error) * 100\n",
        "print(\"Validation Accuracy \" + str(round(accuracy,2)) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 86.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJKq_QDNYBQa",
        "colab_type": "text"
      },
      "source": [
        "###(4) Implementing 2-layer Neural Network using nn and optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC2L_Eys9gjy",
        "colab_type": "text"
      },
      "source": [
        "####Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ltNJEUBzkTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dthOZOtb9mQo",
        "colab_type": "text"
      },
      "source": [
        "####Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPiMGUtg2U86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()\n",
        "x = iris['data']\n",
        "y = iris['target']\n",
        "enc = OneHotEncoder(categories='auto')\n",
        "y = enc.fit_transform(y.reshape(-1,1)).A.astype(np.float32)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHbo5q5u--Ae",
        "colab_type": "text"
      },
      "source": [
        "####Converting numpy arrays into torch.tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xZ0sv7f33pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_trainv = torch.tensor(x_train, requires_grad = False, dtype=torch.float32)\n",
        "y_trainv = torch.tensor(y_train, requires_grad = False, dtype=torch.float32)\n",
        "x_testv = torch.tensor(x_test, requires_grad = False, dtype=torch.float32)\n",
        "y_testv = torch.tensor(y_test, requires_grad = False, dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLKZm2vHOGHC",
        "colab_type": "text"
      },
      "source": [
        "####Building model, loss function, and back propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBRd5L7A50Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#num_in = x.shape[1]\n",
        "#num_h = 5\n",
        "#num_out = y.shape[1]\n",
        "\n",
        "######## TO BE DONE ########## 15% Time: 5 mins\n",
        "#Build your model \n",
        "#model = nn.Sequential(nn.Linear(4,5),nn.Sigmoid())\n",
        "##############################\n",
        "\n",
        "#criterion = nn.MSELoss()\n",
        "\n",
        "######## TO BE DONE ########## 15% Time: 4 mins\n",
        "#Define your optimization module. Use Adam optimization\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters,lr=0.01)\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv0_GqjcFqRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_in = x.shape[1]\n",
        "num_h = 5\n",
        "num_out = y.shape[1]\n",
        "\n",
        "######## TO BE DONE ########## 15% Time: 5 mins\n",
        "#Build your model \n",
        "#q:\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(num_in, num_h),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(num_h, num_out),\n",
        "    nn.Softmax()\n",
        ")##############################\n",
        "\n",
        "\n",
        "######## TO BE DONE ########## 15% Time: 4 mins\n",
        "#Define your optimization module. Use Adam optimization\n",
        "\n",
        "\n",
        "##############################\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use Adam; the optim package contains many other\n",
        "# optimization algoriths. The first argument to the Adam constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alaCLs2vPZPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPMWNTw5OZ1f",
        "colab_type": "text"
      },
      "source": [
        "####Running model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oylMe2Ho7mG8",
        "colab_type": "code",
        "outputId": "a619893a-59fd-4db4-b6c1-f591962dc997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "all_losses = []\n",
        "#x_train=torch.from_numpy(x_train).float()\n",
        "for num in range(7000): #7000 iterations\n",
        "  \n",
        "  ######## TO BE DONE ########## 30% Time: 20 mins\n",
        "  #Predict the output of your model\n",
        "  #Calculate loss\n",
        "  #Append the loss to all_losses list\n",
        "  #Delete the accumulated gradient\n",
        "  #update weights based on loss function you defined earlier\n",
        "\n",
        "  \n",
        "                                              #predict \n",
        "                                              #calculate loss\n",
        "                                              # Append the loss (use loss.data) to all_losses list  \n",
        "                                              #zero gradients to not accumulate \n",
        "                                              #update weights based on loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " pred = model(x_trainv)\n",
        "\n",
        "    # Compute and print loss.\n",
        " loss = criterion(pred, y_trainv)\n",
        " all_losses.append( loss.item())  \n",
        " optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        " loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        " optimizer.step()\n",
        "\n",
        "\n",
        "  ##############################\n",
        "  \n",
        "  \n",
        "\n",
        "all_losses = np.array(all_losses, dtype = np.float)\n",
        "plt.plot(all_losses)\n",
        "plt.show()\n",
        "\n",
        "print(\"Training accuracy = \" + str(round(100-(all_losses[-1]*100),2)) + \" %\")\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy = 99.86 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7QImpnhOdGG",
        "colab_type": "text"
      },
      "source": [
        "####Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9mwkenCBxdd",
        "colab_type": "code",
        "outputId": "41b225ee-a716-40f5-b82b-5cbebba63249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#Validation\n",
        "\n",
        "######## TO BE DONE ########## 20% Time: 10 mins\n",
        "#Validate your model for the test set\n",
        " pred1 =model(x_testv)                           #predict\n",
        " loss =criterion(pred1, y_testv)                        #calculate loss\n",
        " #q:\n",
        "loss_percentage=(100-loss.item())\n",
        "##############################\n",
        "#print(\"Validation accuracy = \" + str(round(100-(loss.item()*100),2)) + \" %\")\n",
        "print(\"Validation accuracy = \" + str(round(loss_percentage,2)) + \" %\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy = 94.24 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bp13JQ8bApW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjX-grUWbtC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}